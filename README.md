# Efficiently_Serving_LLMs
LLM Serving refers to the process of deploying and running large language models (LLMs) to handle user requests. It involves taking an LLM, which is typically trained offline, and setting it up to respond to queries in real-time.
